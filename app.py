import torch
import torch.nn as nn
from torchvision import transforms
from torchvision.models import efficientnet_b0
from PIL import Image
import streamlit as st

# ğŸ§  ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
class SkinCancerModel(nn.Module):
    def __init__(self):
        super(SkinCancerModel, self).__init__()
        self.model = efficientnet_b0(weights=None)
        self.model.classifier[1] = nn.Linear(self.model.classifier[1].in_features, 2)

    def forward(self, x):
        return self.model(x)

# ğŸ§  ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©
model = SkinCancerModel()

model.load_state_dict(torch.load("model.pth", map_location=torch.device('cpu')))


model.eval()

# ğŸŒ€ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„ØµÙˆØ±Ø©
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# ğŸ¨ ÙˆØ§Ø¬Ù‡Ø© Streamlit
st.title("ğŸ”¬ Skin Cancer Detection")
st.write("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù€ skin lesion ÙˆÙ‡Ù‚ÙˆÙ„Ùƒ Ù‡Ù„ ÙÙŠÙ‡Ø§ Ø³Ø±Ø·Ø§Ù† ÙˆÙ„Ø§ Ù„Ø£")

uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø©", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©", use_column_width=True)

    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØµÙˆØ±Ø©
    input_image = transform(image).unsqueeze(0)

    # ØªÙˆÙ‚Ø¹
    with torch.no_grad():
        output = model(input_image)
        prediction = torch.argmax(output, dim=1).item()

    labels = ["Ø³Ù„ÙŠÙ…", "Ø³Ø±Ø·Ø§Ù† Ø¬Ù„Ø¯"]
    st.write(f"ğŸ’¡ Ø§Ù„Ù†ØªÙŠØ¬Ø©: **{labels[prediction]}**")
